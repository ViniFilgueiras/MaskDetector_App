{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé≠ Detec√ß√£o de M√°scara Facial com CNN para ESP32-CAM\n",
                "\n",
                "## Projeto de PDI (Processamento Digital de Imagens)\n",
                "\n",
                "Este notebook implementa um sistema de detec√ß√£o de m√°scara facial usando **Redes Neurais Convolucionais (CNN)**.\n",
                "\n",
                "### O que voc√™ vai aprender:\n",
                "1. Como carregar e visualizar um dataset de imagens\n",
                "2. Como pr√©-processar imagens para Machine Learning\n",
                "3. Como criar uma CNN leve e otimizada\n",
                "4. Como treinar e avaliar o modelo\n",
                "5. Como converter para TensorFlow Lite (para embarcar na ESP32)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ 1. Instala√ß√£o das Bibliotecas\n",
                "\n",
                "Primeiro, vamos instalar todas as bibliotecas necess√°rias. Execute esta c√©lula apenas uma vez."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instala as bibliotecas necess√°rias (execute apenas uma vez)\n",
                "!pip install tensorflow numpy matplotlib scikit-learn opencv-python pillow seaborn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìö 2. Importa√ß√£o das Bibliotecas\n",
                "\n",
                "Aqui importamos todas as bibliotecas que ser√£o usadas no projeto:\n",
                "\n",
                "- **TensorFlow/Keras**: Framework para criar e treinar a CNN\n",
                "- **NumPy**: Manipula√ß√£o de arrays num√©ricos\n",
                "- **Matplotlib/Seaborn**: Visualiza√ß√£o de dados e gr√°ficos\n",
                "- **OpenCV (cv2)**: Processamento de imagens\n",
                "- **Scikit-learn**: Divis√£o de dados e m√©tricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import cv2\n",
                "from PIL import Image\n",
                "\n",
                "# TensorFlow e Keras\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
                "\n",
                "# Scikit-learn para divis√£o de dados e m√©tricas\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "# Configura√ß√µes para visualiza√ß√£o\n",
                "plt.style.use('ggplot')\n",
                "%matplotlib inline\n",
                "\n",
                "# Verificar se TensorFlow est√° usando GPU (se dispon√≠vel)\n",
                "print(f\"TensorFlow vers√£o: {tf.__version__}\")\n",
                "print(f\"GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üóÇÔ∏è 3. Configura√ß√£o dos Caminhos\n",
                "\n",
                "Aqui definimos os caminhos para o dataset e os par√¢metros importantes do projeto.\n",
                "\n",
                "### Par√¢metros Escolhidos:\n",
                "- **IMG_SIZE = 96x96**: Tamanho ideal para ESP32-CAM (balanceia qualidade vs performance)\n",
                "- **Grayscale (1 canal)**: Reduz tamanho do modelo em 3x comparado a RGB\n",
                "- **Batch size = 16**: Pequeno para caber na mem√≥ria limitada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# CONFIGURA√á√ïES DO PROJETO\n",
                "# ============================================\n",
                "\n",
                "# Caminho para o dataset\n",
                "DATASET_PATH = 'dataset_mascaras/data'\n",
                "\n",
                "# Par√¢metros das imagens\n",
                "IMG_SIZE = 96          # Tamanho da imagem (96x96 pixels)\n",
                "IMG_CHANNELS = 1       # 1 = Grayscale, 3 = RGB\n",
                "\n",
                "# Par√¢metros de treinamento\n",
                "BATCH_SIZE = 16        # Quantidade de imagens por lote\n",
                "EPOCHS = 30            # N√∫mero de √©pocas de treinamento\n",
                "VALIDATION_SPLIT = 0.2 # 20% dos dados para valida√ß√£o\n",
                "TEST_SPLIT = 0.1       # 10% dos dados para teste\n",
                "\n",
                "# Classes do problema\n",
                "CLASSES = ['sem_mascara', 'com_mascara']\n",
                "NUM_CLASSES = len(CLASSES)\n",
                "\n",
                "# Seed para reprodutibilidade\n",
                "RANDOM_SEED = 42\n",
                "np.random.seed(RANDOM_SEED)\n",
                "tf.random.set_seed(RANDOM_SEED)\n",
                "\n",
                "print(\"‚úÖ Configura√ß√µes carregadas!\")\n",
                "print(f\"   üìÅ Dataset: {DATASET_PATH}\")\n",
                "print(f\"   üìê Tamanho das imagens: {IMG_SIZE}x{IMG_SIZE}\")\n",
                "print(f\"   üé® Canais: {'Grayscale' if IMG_CHANNELS == 1 else 'RGB'}\")\n",
                "print(f\"   üì¶ Batch size: {BATCH_SIZE}\")\n",
                "print(f\"   üîÑ √âpocas: {EPOCHS}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä 4. Explora√ß√£o do Dataset\n",
                "\n",
                "Antes de treinar o modelo, √© importante entender nosso dataset:\n",
                "- Quantas imagens temos de cada classe?\n",
                "- Como s√£o as imagens?\n",
                "- O dataset est√° balanceado?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conta quantas imagens temos em cada pasta\n",
                "with_mask_path = os.path.join(DATASET_PATH, 'with_mask')\n",
                "without_mask_path = os.path.join(DATASET_PATH, 'without_mask')\n",
                "\n",
                "# Lista os arquivos de cada classe\n",
                "with_mask_files = [f for f in os.listdir(with_mask_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
                "without_mask_files = [f for f in os.listdir(without_mask_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
                "\n",
                "n_with_mask = len(with_mask_files)\n",
                "n_without_mask = len(without_mask_files)\n",
                "total_images = n_with_mask + n_without_mask\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"üìä ESTAT√çSTICAS DO DATASET\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\n‚úÖ Com m√°scara (with_mask):    {n_with_mask} imagens\")\n",
                "print(f\"‚ùå Sem m√°scara (without_mask): {n_without_mask} imagens\")\n",
                "print(f\"\\nüì∏ Total de imagens: {total_images}\")\n",
                "print(f\"\\n‚öñÔ∏è  Propor√ß√£o: {n_with_mask/total_images*100:.1f}% com m√°scara / {n_without_mask/total_images*100:.1f}% sem m√°scara\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualiza√ß√£o da distribui√ß√£o das classes\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Gr√°fico de barras\n",
                "classes_labels = ['Com M√°scara', 'Sem M√°scara']\n",
                "counts = [n_with_mask, n_without_mask]\n",
                "colors = ['#2ecc71', '#e74c3c']\n",
                "\n",
                "axes[0].bar(classes_labels, counts, color=colors, edgecolor='black')\n",
                "axes[0].set_title('Distribui√ß√£o das Classes', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('Quantidade de Imagens')\n",
                "for i, (count, label) in enumerate(zip(counts, classes_labels)):\n",
                "    axes[0].text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
                "\n",
                "# Gr√°fico de pizza\n",
                "axes[1].pie(counts, labels=classes_labels, colors=colors, autopct='%1.1f%%',\n",
                "            startangle=90, explode=(0.05, 0.05))\n",
                "axes[1].set_title('Propor√ß√£o das Classes', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('distribuicao_dataset.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüíæ Gr√°fico salvo como 'distribuicao_dataset.png'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üñºÔ∏è 5. Visualiza√ß√£o de Amostras\n",
                "\n",
                "Vamos ver algumas imagens do dataset para entender como s√£o os dados."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def mostrar_amostras(pasta, titulo, n_amostras=5):\n",
                "    \"\"\"\n",
                "    Mostra amostras de imagens de uma pasta.\n",
                "    \n",
                "    Args:\n",
                "        pasta: Caminho para a pasta com as imagens\n",
                "        titulo: T√≠tulo para o gr√°fico\n",
                "        n_amostras: N√∫mero de amostras a mostrar\n",
                "    \"\"\"\n",
                "    arquivos = [f for f in os.listdir(pasta) if f.endswith(('.jpg', '.jpeg', '.png'))][:n_amostras]\n",
                "    \n",
                "    fig, axes = plt.subplots(1, n_amostras, figsize=(15, 3))\n",
                "    fig.suptitle(titulo, fontsize=14, fontweight='bold')\n",
                "    \n",
                "    for idx, arquivo in enumerate(arquivos):\n",
                "        img_path = os.path.join(pasta, arquivo)\n",
                "        img = Image.open(img_path)\n",
                "        \n",
                "        axes[idx].imshow(img)\n",
                "        axes[idx].axis('off')\n",
                "        axes[idx].set_title(f'{img.size[0]}x{img.size[1]}', fontsize=10)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Mostra amostras de cada classe\n",
                "print(\"\\nüé≠ AMOSTRAS COM M√ÅSCARA:\\n\")\n",
                "mostrar_amostras(with_mask_path, '‚úÖ Imagens COM M√°scara')\n",
                "\n",
                "print(\"\\nüò∑ AMOSTRAS SEM M√ÅSCARA:\\n\")\n",
                "mostrar_amostras(without_mask_path, '‚ùå Imagens SEM M√°scara')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîß 6. Pr√©-processamento das Imagens\n",
                "\n",
                "Agora vamos preparar as imagens para o treinamento:\n",
                "\n",
                "1. **Redimensionar** para 96x96 pixels (padr√£o para ESP32-CAM)\n",
                "2. **Converter para grayscale** (economia de mem√≥ria)\n",
                "3. **Normalizar** valores de 0-255 para 0-1\n",
                "4. **Criar labels** (0 = sem m√°scara, 1 = com m√°scara)\n",
                "\n",
                "### Por que 96x96?\n",
                "- A ESP32-CAM tem apenas ~520KB de RAM\n",
                "- Imagens menores = modelo menor = mais r√°pido\n",
                "- 96x96 √© um bom equil√≠brio entre qualidade e performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def carregar_e_preprocessar_imagem(caminho_imagem, tamanho=IMG_SIZE, grayscale=True):\n",
                "    \"\"\"\n",
                "    Carrega uma imagem e aplica o pr√©-processamento.\n",
                "    \n",
                "    Args:\n",
                "        caminho_imagem: Caminho para o arquivo da imagem\n",
                "        tamanho: Tamanho final da imagem (tamanho x tamanho)\n",
                "        grayscale: Se True, converte para escala de cinza\n",
                "    \n",
                "    Returns:\n",
                "        Imagem pr√©-processada como array numpy\n",
                "    \"\"\"\n",
                "    # L√™ a imagem\n",
                "    if grayscale:\n",
                "        img = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
                "    else:\n",
                "        img = cv2.imread(caminho_imagem)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Redimensiona para o tamanho desejado\n",
                "    img = cv2.resize(img, (tamanho, tamanho))\n",
                "    \n",
                "    # Normaliza para valores entre 0 e 1\n",
                "    img = img.astype('float32') / 255.0\n",
                "    \n",
                "    return img\n",
                "\n",
                "print(\"‚úÖ Fun√ß√£o de pr√©-processamento definida!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def carregar_dataset(dataset_path, img_size=IMG_SIZE, grayscale=True):\n",
                "    \"\"\"\n",
                "    Carrega todo o dataset e aplica pr√©-processamento.\n",
                "    \n",
                "    Args:\n",
                "        dataset_path: Caminho para a pasta do dataset\n",
                "        img_size: Tamanho das imagens\n",
                "        grayscale: Se True, converte para grayscale\n",
                "    \n",
                "    Returns:\n",
                "        X: Array com as imagens\n",
                "        y: Array com as labels (0 = sem m√°scara, 1 = com m√°scara)\n",
                "    \"\"\"\n",
                "    imagens = []\n",
                "    labels = []\n",
                "    \n",
                "    # Carrega imagens SEM m√°scara (label = 0)\n",
                "    print(\"üìÇ Carregando imagens SEM m√°scara...\")\n",
                "    pasta_sem_mascara = os.path.join(dataset_path, 'without_mask')\n",
                "    for arquivo in os.listdir(pasta_sem_mascara):\n",
                "        if arquivo.endswith(('.jpg', '.jpeg', '.png')):\n",
                "            caminho = os.path.join(pasta_sem_mascara, arquivo)\n",
                "            try:\n",
                "                img = carregar_e_preprocessar_imagem(caminho, img_size, grayscale)\n",
                "                imagens.append(img)\n",
                "                labels.append(0)  # 0 = sem m√°scara\n",
                "            except Exception as e:\n",
                "                print(f\"   ‚ö†Ô∏è Erro ao carregar {arquivo}: {e}\")\n",
                "    \n",
                "    # Carrega imagens COM m√°scara (label = 1)\n",
                "    print(\"üìÇ Carregando imagens COM m√°scara...\")\n",
                "    pasta_com_mascara = os.path.join(dataset_path, 'with_mask')\n",
                "    for arquivo in os.listdir(pasta_com_mascara):\n",
                "        if arquivo.endswith(('.jpg', '.jpeg', '.png')):\n",
                "            caminho = os.path.join(pasta_com_mascara, arquivo)\n",
                "            try:\n",
                "                img = carregar_e_preprocessar_imagem(caminho, img_size, grayscale)\n",
                "                imagens.append(img)\n",
                "                labels.append(1)  # 1 = com m√°scara\n",
                "            except Exception as e:\n",
                "                print(f\"   ‚ö†Ô∏è Erro ao carregar {arquivo}: {e}\")\n",
                "    \n",
                "    # Converte para arrays numpy\n",
                "    X = np.array(imagens)\n",
                "    y = np.array(labels)\n",
                "    \n",
                "    # Adiciona dimens√£o do canal se grayscale\n",
                "    if grayscale and len(X.shape) == 3:\n",
                "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
                "    \n",
                "    print(f\"\\n‚úÖ Dataset carregado com sucesso!\")\n",
                "    print(f\"   üìä Shape das imagens: {X.shape}\")\n",
                "    print(f\"   üìä Shape das labels: {y.shape}\")\n",
                "    \n",
                "    return X, y\n",
                "\n",
                "# Carrega o dataset\n",
                "X, y = carregar_dataset(DATASET_PATH, IMG_SIZE, grayscale=(IMG_CHANNELS == 1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualiza algumas imagens pr√©-processadas\n",
                "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
                "fig.suptitle('Imagens Pr√©-processadas (96x96 Grayscale)', fontsize=14, fontweight='bold')\n",
                "\n",
                "# √çndices aleat√≥rios para visualiza√ß√£o\n",
                "indices_sem_mascara = np.where(y == 0)[0][:5]\n",
                "indices_com_mascara = np.where(y == 1)[0][:5]\n",
                "\n",
                "# Mostra imagens sem m√°scara (primeira linha)\n",
                "for i, idx in enumerate(indices_sem_mascara):\n",
                "    axes[0, i].imshow(X[idx].squeeze(), cmap='gray')\n",
                "    axes[0, i].axis('off')\n",
                "    axes[0, i].set_title('Sem M√°scara', color='red', fontsize=10)\n",
                "\n",
                "# Mostra imagens com m√°scara (segunda linha)\n",
                "for i, idx in enumerate(indices_com_mascara):\n",
                "    axes[1, i].imshow(X[idx].squeeze(), cmap='gray')\n",
                "    axes[1, i].axis('off')\n",
                "    axes[1, i].set_title('Com M√°scara', color='green', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('imagens_preprocessadas.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüíæ Gr√°fico salvo como 'imagens_preprocessadas.png'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÇÔ∏è 7. Divis√£o dos Dados\n",
                "\n",
                "Dividimos o dataset em tr√™s partes:\n",
                "\n",
                "- **Treino (70%)**: Usado para treinar a rede neural\n",
                "- **Valida√ß√£o (20%)**: Usado para ajustar hiperpar√¢metros e evitar overfitting\n",
                "- **Teste (10%)**: Usado apenas no final para avaliar o modelo\n",
                "\n",
                "‚ö†Ô∏è **Importante**: O conjunto de teste NUNCA √© visto durante o treinamento!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Primeiro, separa conjunto de teste\n",
                "X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=TEST_SPLIT, \n",
                "    random_state=RANDOM_SEED,\n",
                "    stratify=y  # Mant√©m a propor√ß√£o das classes\n",
                ")\n",
                "\n",
                "# Depois, separa treino e valida√ß√£o\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_temp, y_temp,\n",
                "    test_size=VALIDATION_SPLIT / (1 - TEST_SPLIT),  # Ajusta a propor√ß√£o\n",
                "    random_state=RANDOM_SEED,\n",
                "    stratify=y_temp\n",
                ")\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"üìä DIVIS√ÉO DO DATASET\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\nüèãÔ∏è Treino:     {len(X_train)} imagens ({len(X_train)/len(X)*100:.1f}%)\")\n",
                "print(f\"   - Sem m√°scara: {np.sum(y_train == 0)}\")\n",
                "print(f\"   - Com m√°scara: {np.sum(y_train == 1)}\")\n",
                "\n",
                "print(f\"\\nüìã Valida√ß√£o:  {len(X_val)} imagens ({len(X_val)/len(X)*100:.1f}%)\")\n",
                "print(f\"   - Sem m√°scara: {np.sum(y_val == 0)}\")\n",
                "print(f\"   - Com m√°scara: {np.sum(y_val == 1)}\")\n",
                "\n",
                "print(f\"\\nüß™ Teste:      {len(X_test)} imagens ({len(X_test)/len(X)*100:.1f}%)\")\n",
                "print(f\"   - Sem m√°scara: {np.sum(y_test == 0)}\")\n",
                "print(f\"   - Com m√°scara: {np.sum(y_test == 1)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† 8. Cria√ß√£o da CNN (Rede Neural Convolucional)\n",
                "\n",
                "Agora vamos criar a arquitetura da CNN. √â uma rede **leve e otimizada** para rodar na ESP32-CAM.\n",
                "\n",
                "### Arquitetura da Rede:\n",
                "\n",
                "```\n",
                "Entrada: 96x96x1 (imagem grayscale)\n",
                "    ‚Üì\n",
                "Conv2D (8 filtros, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
                "    ‚Üì\n",
                "Conv2D (16 filtros, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
                "    ‚Üì\n",
                "Conv2D (32 filtros, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool\n",
                "    ‚Üì\n",
                "Flatten ‚Üí Dense (32) ‚Üí Dropout (0.5)\n",
                "    ‚Üì\n",
                "Dense (1) ‚Üí Sigmoid\n",
                "    ‚Üì\n",
                "Sa√≠da: 0 (sem m√°scara) ou 1 (com m√°scara)\n",
                "```\n",
                "\n",
                "### Por que esta arquitetura?\n",
                "- **Poucos filtros**: Reduz o tamanho do modelo\n",
                "- **BatchNormalization**: Acelera o treinamento e estabiliza\n",
                "- **Dropout**: Previne overfitting com dataset pequeno\n",
                "- **Sa√≠da sigmoid**: Classifica√ß√£o bin√°ria"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def criar_modelo_cnn(input_shape=(IMG_SIZE, IMG_SIZE, IMG_CHANNELS)):\n",
                "    \"\"\"\n",
                "    Cria uma CNN leve otimizada para ESP32-CAM.\n",
                "    \n",
                "    Args:\n",
                "        input_shape: Formato da entrada (altura, largura, canais)\n",
                "    \n",
                "    Returns:\n",
                "        Modelo Keras compilado\n",
                "    \"\"\"\n",
                "    model = models.Sequential([\n",
                "        # Camada de entrada\n",
                "        layers.Input(shape=input_shape),\n",
                "        \n",
                "        # Bloco Convolucional 1\n",
                "        layers.Conv2D(8, (3, 3), padding='same'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Activation('relu'),\n",
                "        layers.MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Bloco Convolucional 2\n",
                "        layers.Conv2D(16, (3, 3), padding='same'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Activation('relu'),\n",
                "        layers.MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Bloco Convolucional 3\n",
                "        layers.Conv2D(32, (3, 3), padding='same'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Activation('relu'),\n",
                "        layers.MaxPooling2D((2, 2)),\n",
                "        \n",
                "        # Camadas Densas (Fully Connected)\n",
                "        layers.Flatten(),\n",
                "        layers.Dense(32, activation='relu'),\n",
                "        layers.Dropout(0.5),  # Previne overfitting\n",
                "        \n",
                "        # Camada de sa√≠da (classifica√ß√£o bin√°ria)\n",
                "        layers.Dense(1, activation='sigmoid')\n",
                "    ])\n",
                "    \n",
                "    # Compila o modelo\n",
                "    model.compile(\n",
                "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
                "        loss='binary_crossentropy',\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Cria o modelo\n",
                "modelo = criar_modelo_cnn()\n",
                "\n",
                "# Mostra o resumo da arquitetura\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üß† ARQUITETURA DA CNN\")\n",
                "print(\"=\"*60)\n",
                "modelo.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcula o tamanho do modelo\n",
                "num_params = modelo.count_params()\n",
                "tamanho_estimado_mb = (num_params * 4) / (1024 * 1024)  # 4 bytes por par√¢metro (float32)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"üìè TAMANHO DO MODELO\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\nüî¢ Total de par√¢metros: {num_params:,}\")\n",
                "print(f\"üì¶ Tamanho estimado: {tamanho_estimado_mb:.2f} MB (float32)\")\n",
                "print(f\"üì¶ Tamanho quantizado: ~{tamanho_estimado_mb/4:.2f} MB (int8)\")\n",
                "\n",
                "if tamanho_estimado_mb < 1:\n",
                "    print(\"\\n‚úÖ Modelo adequado para ESP32-CAM!\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è Modelo pode ser grande demais. Considere reduzir os filtros.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÑ 9. Data Augmentation (Aumento de Dados)\n",
                "\n",
                "Como nosso dataset √© pequeno, usamos **data augmentation** para criar varia√ß√µes das imagens:\n",
                "\n",
                "- **Rota√ß√£o**: Pequenas rota√ß√µes (-10¬∞ a +10¬∞)\n",
                "- **Zoom**: Pequeno zoom (90% a 110%)\n",
                "- **Flip horizontal**: Espelha a imagem\n",
                "- **Shift**: Pequenos deslocamentos\n",
                "\n",
                "Isso ajuda o modelo a generalizar melhor e **previne overfitting**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cria geradores de data augmentation\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rotation_range=10,           # Rota√ß√£o de -10¬∞ a +10¬∞\n",
                "    width_shift_range=0.1,       # Deslocamento horizontal\n",
                "    height_shift_range=0.1,      # Deslocamento vertical\n",
                "    zoom_range=0.1,              # Zoom de 90% a 110%\n",
                "    horizontal_flip=True,        # Espelhamento horizontal\n",
                "    fill_mode='nearest'          # Preenche pixels vazios\n",
                ")\n",
                "\n",
                "# Para valida√ß√£o, n√£o aplicamos augmentation\n",
                "val_datagen = ImageDataGenerator()\n",
                "\n",
                "print(\"‚úÖ Data augmentation configurado!\")\n",
                "print(\"\\nüì∑ Transforma√ß√µes aplicadas no treino:\")\n",
                "print(\"   ‚Ä¢ Rota√ß√£o: ¬±10¬∞\")\n",
                "print(\"   ‚Ä¢ Shift: ¬±10%\")\n",
                "print(\"   ‚Ä¢ Zoom: ¬±10%\")\n",
                "print(\"   ‚Ä¢ Flip horizontal: Sim\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualiza exemplos de data augmentation\n",
                "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
                "fig.suptitle('Exemplos de Data Augmentation', fontsize=14, fontweight='bold')\n",
                "\n",
                "# Pega uma imagem de exemplo\n",
                "img_exemplo = X_train[0:1]\n",
                "\n",
                "# Gera 10 varia√ß√µes\n",
                "augmented_images = [train_datagen.random_transform(img_exemplo[0]) for _ in range(10)]\n",
                "\n",
                "for i, img in enumerate(augmented_images):\n",
                "    row = i // 5\n",
                "    col = i % 5\n",
                "    axes[row, col].imshow(img.squeeze(), cmap='gray')\n",
                "    axes[row, col].axis('off')\n",
                "    axes[row, col].set_title(f'Varia√ß√£o {i+1}', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('data_augmentation.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüíæ Gr√°fico salvo como 'data_augmentation.png'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèãÔ∏è 10. Treinamento do Modelo\n",
                "\n",
                "Agora vamos treinar a CNN! Usamos duas t√©cnicas importantes:\n",
                "\n",
                "1. **Early Stopping**: Para o treinamento se a valida√ß√£o n√£o melhorar\n",
                "2. **Model Checkpoint**: Salva o melhor modelo durante o treinamento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks para monitorar o treinamento\n",
                "callbacks = [\n",
                "    # Para o treino se a valida√ß√£o n√£o melhorar por 5 √©pocas\n",
                "    EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=5,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    # Salva o melhor modelo\n",
                "    ModelCheckpoint(\n",
                "        'melhor_modelo.keras',\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"‚úÖ Callbacks configurados!\")\n",
                "print(\"   ‚Ä¢ EarlyStopping: patience=5\")\n",
                "print(\"   ‚Ä¢ ModelCheckpoint: salva em 'melhor_modelo.keras'\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Treina o modelo\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üèãÔ∏è INICIANDO TREINAMENTO\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\n‚è±Ô∏è √âpocas m√°ximas: {EPOCHS}\")\n",
                "print(f\"üì¶ Batch size: {BATCH_SIZE}\")\n",
                "print(f\"üîÑ Data Augmentation: Ativado\\n\")\n",
                "\n",
                "# Cria os geradores\n",
                "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
                "val_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n",
                "\n",
                "# Treina!\n",
                "historico = modelo.fit(\n",
                "    train_generator,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=val_generator,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TREINAMENTO CONCLU√çDO!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìà 11. Visualiza√ß√£o do Treinamento\n",
                "\n",
                "Vamos ver como o modelo aprendeu ao longo das √©pocas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plotar_historico(historico):\n",
                "    \"\"\"\n",
                "    Plota os gr√°ficos de loss e accuracy durante o treinamento.\n",
                "    \"\"\"\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    \n",
                "    # Gr√°fico de Loss\n",
                "    axes[0].plot(historico.history['loss'], label='Treino', linewidth=2)\n",
                "    axes[0].plot(historico.history['val_loss'], label='Valida√ß√£o', linewidth=2)\n",
                "    axes[0].set_title('Loss ao Longo do Treinamento', fontsize=14, fontweight='bold')\n",
                "    axes[0].set_xlabel('√âpoca')\n",
                "    axes[0].set_ylabel('Loss')\n",
                "    axes[0].legend()\n",
                "    axes[0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Gr√°fico de Accuracy\n",
                "    axes[1].plot(historico.history['accuracy'], label='Treino', linewidth=2)\n",
                "    axes[1].plot(historico.history['val_accuracy'], label='Valida√ß√£o', linewidth=2)\n",
                "    axes[1].set_title('Acur√°cia ao Longo do Treinamento', fontsize=14, fontweight='bold')\n",
                "    axes[1].set_xlabel('√âpoca')\n",
                "    axes[1].set_ylabel('Acur√°cia')\n",
                "    axes[1].legend()\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('historico_treinamento.png', dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print(\"\\nüíæ Gr√°fico salvo como 'historico_treinamento.png'\")\n",
                "\n",
                "# Plota o hist√≥rico\n",
                "plotar_historico(historico)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ 12. Avalia√ß√£o do Modelo\n",
                "\n",
                "Agora vamos avaliar o modelo no conjunto de **teste** (dados que ele nunca viu!)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Avalia no conjunto de teste\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üß™ AVALIA√á√ÉO NO CONJUNTO DE TESTE\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "test_loss, test_accuracy = modelo.evaluate(X_test, y_test, verbose=0)\n",
                "\n",
                "print(f\"\\nüìä Resultados no Conjunto de Teste:\")\n",
                "print(f\"   ‚Ä¢ Loss: {test_loss:.4f}\")\n",
                "print(f\"   ‚Ä¢ Acur√°cia: {test_accuracy*100:.2f}%\")\n",
                "\n",
                "if test_accuracy >= 0.90:\n",
                "    print(\"\\nüéâ Excelente! Acur√°cia acima de 90%!\")\n",
                "elif test_accuracy >= 0.80:\n",
                "    print(\"\\n‚úÖ Bom! Acur√°cia acima de 80%!\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è Acur√°cia abaixo de 80%. Considere mais dados ou ajustes.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Faz predi√ß√µes no conjunto de teste\n",
                "y_pred_prob = modelo.predict(X_test)\n",
                "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
                "\n",
                "# Matriz de Confus√£o\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['Sem M√°scara', 'Com M√°scara'],\n",
                "            yticklabels=['Sem M√°scara', 'Com M√°scara'])\n",
                "plt.title('Matriz de Confus√£o', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Predi√ß√£o')\n",
                "plt.ylabel('Real')\n",
                "plt.tight_layout()\n",
                "plt.savefig('matriz_confusao.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüíæ Gr√°fico salvo como 'matriz_confusao.png'\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Relat√≥rio de Classifica√ß√£o\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üìã RELAT√ìRIO DE CLASSIFICA√á√ÉO\")\n",
                "print(\"=\"*60)\n",
                "print(classification_report(y_test, y_pred, target_names=['Sem M√°scara', 'Com M√°scara']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÆ 13. Testando com Novas Imagens\n",
                "\n",
                "Vamos criar uma fun√ß√£o para testar o modelo com imagens individuais."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prever_mascara(caminho_imagem, modelo, mostrar=True):\n",
                "    \"\"\"\n",
                "    Faz a predi√ß√£o para uma √∫nica imagem.\n",
                "    \n",
                "    Args:\n",
                "        caminho_imagem: Caminho para a imagem\n",
                "        modelo: Modelo treinado\n",
                "        mostrar: Se True, mostra a imagem com a predi√ß√£o\n",
                "    \n",
                "    Returns:\n",
                "        Predi√ß√£o (0 = sem m√°scara, 1 = com m√°scara) e probabilidade\n",
                "    \"\"\"\n",
                "    # Carrega e pr√©-processa a imagem\n",
                "    img = carregar_e_preprocessar_imagem(caminho_imagem, IMG_SIZE, grayscale=True)\n",
                "    img_batch = img.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
                "    \n",
                "    # Faz a predi√ß√£o\n",
                "    probabilidade = modelo.predict(img_batch, verbose=0)[0][0]\n",
                "    predicao = 1 if probabilidade > 0.5 else 0\n",
                "    \n",
                "    # Mostra a imagem se solicitado\n",
                "    if mostrar:\n",
                "        plt.figure(figsize=(6, 6))\n",
                "        \n",
                "        # Carrega a imagem original para visualiza√ß√£o\n",
                "        img_original = Image.open(caminho_imagem)\n",
                "        plt.imshow(img_original)\n",
                "        \n",
                "        if predicao == 1:\n",
                "            titulo = f\"‚úÖ COM M√ÅSCARA ({probabilidade*100:.1f}%)\"\n",
                "            cor = 'green'\n",
                "        else:\n",
                "            titulo = f\"‚ùå SEM M√ÅSCARA ({(1-probabilidade)*100:.1f}%)\"\n",
                "            cor = 'red'\n",
                "        \n",
                "        plt.title(titulo, fontsize=14, fontweight='bold', color=cor)\n",
                "        plt.axis('off')\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "    \n",
                "    return predicao, probabilidade\n",
                "\n",
                "print(\"‚úÖ Fun√ß√£o de predi√ß√£o criada!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Testa com algumas imagens do dataset\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üîÆ TESTANDO PREDI√á√ïES\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Testa imagem com m√°scara\n",
                "img_com_mascara = os.path.join(with_mask_path, with_mask_files[0])\n",
                "print(f\"\\nüì∏ Testando: {with_mask_files[0]}\")\n",
                "prever_mascara(img_com_mascara, modelo)\n",
                "\n",
                "# Testa imagem sem m√°scara\n",
                "img_sem_mascara = os.path.join(without_mask_path, without_mask_files[0])\n",
                "print(f\"\\nüì∏ Testando: {without_mask_files[0]}\")\n",
                "prever_mascara(img_sem_mascara, modelo)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ 14. Salvando o Modelo\n",
                "\n",
                "Agora vamos salvar o modelo em diferentes formatos:\n",
                "\n",
                "1. **Keras (.keras)**: Formato nativo, f√°cil de carregar no Python\n",
                "2. **TensorFlow Lite (.tflite)**: Formato otimizado para dispositivos embarcados como ESP32"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Salva o modelo no formato Keras\n",
                "modelo.save('modelo_mascara.keras')\n",
                "print(\"‚úÖ Modelo salvo como 'modelo_mascara.keras'\")\n",
                "\n",
                "# Tamb√©m salva os pesos separadamente\n",
                "modelo.save_weights('pesos_mascara.weights.h5')\n",
                "print(\"‚úÖ Pesos salvos como 'pesos_mascara.weights.h5'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì± 15. Convers√£o para TensorFlow Lite\n",
                "\n",
                "Para rodar na ESP32-CAM, precisamos converter o modelo para **TensorFlow Lite** e **quantizar** (converter de float32 para int8).\n",
                "\n",
                "### Benef√≠cios da Quantiza√ß√£o:\n",
                "- Reduz o tamanho do modelo em **~4x**\n",
                "- Acelera a infer√™ncia na ESP32\n",
                "- Usa menos mem√≥ria RAM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Converte para TensorFlow Lite (sem quantiza√ß√£o)\n",
                "converter = tf.lite.TFLiteConverter.from_keras_model(modelo)\n",
                "tflite_model = converter.convert()\n",
                "\n",
                "# Salva o modelo TFLite\n",
                "with open('modelo_mascara.tflite', 'wb') as f:\n",
                "    f.write(tflite_model)\n",
                "\n",
                "tamanho_tflite = len(tflite_model) / 1024\n",
                "print(f\"\\n‚úÖ Modelo TFLite salvo!\")\n",
                "print(f\"   üì¶ Tamanho: {tamanho_tflite:.2f} KB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convers√£o com quantiza√ß√£o INT8 (otimizado para ESP32)\n",
                "def representative_dataset():\n",
                "    \"\"\"Gera dados representativos para calibra√ß√£o da quantiza√ß√£o.\"\"\"\n",
                "    for i in range(min(100, len(X_train))):\n",
                "        yield [X_train[i:i+1].astype(np.float32)]\n",
                "\n",
                "# Configura o conversor para quantiza√ß√£o completa\n",
                "converter_quant = tf.lite.TFLiteConverter.from_keras_model(modelo)\n",
                "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
                "converter_quant.representative_dataset = representative_dataset\n",
                "converter_quant.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
                "converter_quant.inference_input_type = tf.uint8\n",
                "converter_quant.inference_output_type = tf.uint8\n",
                "\n",
                "try:\n",
                "    tflite_model_quant = converter_quant.convert()\n",
                "    \n",
                "    # Salva o modelo quantizado\n",
                "    with open('modelo_mascara_quant.tflite', 'wb') as f:\n",
                "        f.write(tflite_model_quant)\n",
                "    \n",
                "    tamanho_quant = len(tflite_model_quant) / 1024\n",
                "    print(f\"\\n‚úÖ Modelo TFLite Quantizado (INT8) salvo!\")\n",
                "    print(f\"   üì¶ Tamanho: {tamanho_quant:.2f} KB\")\n",
                "    print(f\"   üìâ Redu√ß√£o: {(1 - tamanho_quant/tamanho_tflite)*100:.1f}%\")\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ö†Ô∏è Quantiza√ß√£o INT8 completa falhou: {e}\")\n",
                "    print(\"   Usando quantiza√ß√£o h√≠brida...\")\n",
                "    \n",
                "    converter_hybrid = tf.lite.TFLiteConverter.from_keras_model(modelo)\n",
                "    converter_hybrid.optimizations = [tf.lite.Optimize.DEFAULT]\n",
                "    tflite_model_hybrid = converter_hybrid.convert()\n",
                "    \n",
                "    with open('modelo_mascara_quant.tflite', 'wb') as f:\n",
                "        f.write(tflite_model_hybrid)\n",
                "    \n",
                "    tamanho_hybrid = len(tflite_model_hybrid) / 1024\n",
                "    print(f\"\\n‚úÖ Modelo TFLite com quantiza√ß√£o h√≠brida salvo!\")\n",
                "    print(f\"   üì¶ Tamanho: {tamanho_hybrid:.2f} KB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä 16. Resumo Final\n",
                "\n",
                "Vamos ver um resumo de tudo que foi feito!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resumo final\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"üìä RESUMO DO PROJETO\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(f\"\"\"\n",
                "üóÇÔ∏è DATASET:\n",
                "   ‚Ä¢ Total de imagens: {total_images}\n",
                "   ‚Ä¢ Com m√°scara: {n_with_mask}\n",
                "   ‚Ä¢ Sem m√°scara: {n_without_mask}\n",
                "\n",
                "üñºÔ∏è PR√â-PROCESSAMENTO:\n",
                "   ‚Ä¢ Tamanho: {IMG_SIZE}x{IMG_SIZE} pixels\n",
                "   ‚Ä¢ Canais: {'Grayscale' if IMG_CHANNELS == 1 else 'RGB'}\n",
                "   ‚Ä¢ Normaliza√ß√£o: 0-1\n",
                "\n",
                "üß† MODELO CNN:\n",
                "   ‚Ä¢ Camadas convolucionais: 3\n",
                "   ‚Ä¢ Filtros: 8 ‚Üí 16 ‚Üí 32\n",
                "   ‚Ä¢ Total de par√¢metros: {modelo.count_params():,}\n",
                "\n",
                "üìà RESULTADOS:\n",
                "   ‚Ä¢ Acur√°cia no teste: {test_accuracy*100:.2f}%\n",
                "   ‚Ä¢ Loss no teste: {test_loss:.4f}\n",
                "\n",
                "üíæ ARQUIVOS GERADOS:\n",
                "   ‚Ä¢ modelo_mascara.keras (Keras)\n",
                "   ‚Ä¢ modelo_mascara.tflite (TensorFlow Lite)\n",
                "   ‚Ä¢ modelo_mascara_quant.tflite (Quantizado para ESP32)\n",
                "\"\"\")\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"üéâ PROJETO CONCLU√çDO COM SUCESSO!\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üöÄ Pr√≥ximos Passos (para a ESP32-CAM)\n",
                "\n",
                "Quando voc√™ tiver a ESP32-CAM, os pr√≥ximos passos ser√£o:\n",
                "\n",
                "1. **Converter o modelo para C array** (header file .h)\n",
                "2. **Configurar o TensorFlow Lite Micro** na ESP32\n",
                "3. **Capturar imagens da c√¢mera** e pr√©-processar\n",
                "4. **Rodar infer√™ncia** e mostrar resultado\n",
                "\n",
                "### Comando para converter TFLite para C array:\n",
                "```bash\n",
                "xxd -i modelo_mascara_quant.tflite > modelo_mascara.h\n",
                "```\n",
                "\n",
                "---\n",
                "\n",
                "**Autor:** Projeto de PDI - Detec√ß√£o de M√°scara Facial  \n",
                "**Data:** Dezembro 2024"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}