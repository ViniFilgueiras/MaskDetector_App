{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\ude37 Face Mask Detector (Ultra Light \u26a1)\n",
    "\n",
    "## \ud83d\udccb Sobre esta Vers\u00e3o\n",
    "Esta \u00e9 uma vers\u00e3o otimizada para **tamanho extremo (< 400KB)**.\n",
    "Diferente da vers\u00e3o padr\u00e3o, esta **N\u00c3O usa Transfer Learning** da ImageNet, pois para atingir tamanhos t\u00e3o pequenos, precisamos usar uma arquitetura MobileNetV2 com `alpha=0.1`, para a qual n\u00e3o existem pesos p\u00fablicos pr\u00e9-treinados.\n",
    "\n",
    "**Consequ\u00eancia**: O modelo ser\u00e1 treinado **do zero** (`scratch`).\n",
    "\n",
    "## \ud83c\udfaf Fases do Projeto\n",
    "1. **Prepara\u00e7\u00e3o dos Dados**: Download e pr\u00e9-processamento.\n",
    "2. **Data Augmentation**: Essencial aqui, pois vamos aprender do zero.\n",
    "3. **Treinamento Completo**: Uma \u00fanica fase longa de treinamento.\n",
    "4. **Exporta\u00e7\u00e3o**: Convers\u00e3o para TFLite (INT8).\n",
    "\n",
    "---\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \ud83d\udee0\ufe0f Configura\u00e7\u00e3o Inicial\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "\n",
    "# Utilit\u00e1rios do Keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Constantes e Hiperpar\u00e2metros\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (64, 64) \n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "SEED = 42\n",
    "\n",
    "print(f\"Vers\u00e3o do TensorFlow: {tf.__version__}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \ud83d\udce5 Download dos Dados (KaggleHub)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2b07\ufe0f Baixando Dataset...\")\n",
    "path = kagglehub.dataset_download(\"omkargurav/face-mask-dataset\")\n",
    "DATA_DIR = os.path.join(path, \"data\")\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"\ud83c\udff7\ufe0f Classes: {class_names}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \ud83c\udfa8 Visualiza\u00e7\u00e3o\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega uma imagem crua para visualiza\u00e7\u00e3o\n",
    "all_image_paths = glob.glob(os.path.join(DATA_DIR, \"*\", \"*.jpg\"))\n",
    "if not all_image_paths: # Fallback se n\u00e3o achar jpg\n",
    "    all_image_paths = glob.glob(os.path.join(DATA_DIR, \"*\", \"*\"))\n",
    "    \n",
    "random_image_path = random.choice(all_image_paths)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. \u2699\ufe0f Pr\u00e9-processamento e Augmentation\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "def preprocess_train(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "def preprocess_val(image, label):\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_train, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "validation_dataset = validation_dataset.map(preprocess_val, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. \ud83c\udfd7\ufe0f Constru\u00e7\u00e3o do Modelo (Ultra-Leve)\n",
    "Aqui est\u00e1 a mudan\u00e7a chave: `weights=None` e `alpha=0.1`.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83c\udfd7\ufe0f Construindo MobileNetV2 do ZERO (Alpha=0.1)...\")\n",
    "\n",
    "# Base Ultra Leve\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    include_top=False,\n",
    "    weights=None,   # <--- Sem pesos pr\u00e9-treinados\n",
    "    alpha=0.1       # <--- Rede extremamente pequena (~10% do tamanho original)\n",
    ")\n",
    "\n",
    "# Como n\u00e3o tem pesos pr\u00e9-treinados, treinamos TUDO desde o in\u00edcio\n",
    "base_model.trainable = True\n",
    "\n",
    "inputs = Input(shape=IMG_SHAPE)\n",
    "x = base_model(inputs)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x) # Dropout menor pois a rede j\u00e1 \u00e9 pequena e tem poucos params\n",
    "outputs = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3), # LR normal para come\u00e7ar do zero\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. \ud83d\ude80 Treinamento (Scratch)\n",
    "Treinamos por mais \u00e9pocas (30-40) para compensar a falta de pr\u00e9-treino.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "print(\"\\n\ud83d\ude80 Iniciando Treinamento Completo...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=40, # Mais \u00e9pocas\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. \ud83d\udcca Resultados\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Treino Acc')\n",
    "plt.plot(val_acc, label='Valida\u00e7\u00e3o Acc')\n",
    "plt.legend()\n",
    "plt.title('Acur\u00e1cia')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Treino Loss')\n",
    "plt.plot(val_loss, label='Valida\u00e7\u00e3o Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Diagn\u00f3stico de Overfitting\n",
    "final_train_acc = acc[-1]\n",
    "final_val_acc = val_acc[-1]\n",
    "gap = final_train_acc - final_val_acc\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Diagn\u00f3stico Final:\")\n",
    "print(f\"   Acur\u00e1cia Treino: {final_train_acc*100:.2f}%\")\n",
    "print(f\"   Acur\u00e1cia Valida\u00e7\u00e3o: {final_val_acc*100:.2f}%\")\n",
    "print(f\"   GAP: {gap*100:.2f}%\")\n",
    "\n",
    "if gap > 0.10:\n",
    "    print(\"\u26a0\ufe0f ALERTA: Poss\u00edvel Overfitting (Gap > 10%)\")\n",
    "else:\n",
    "    print(\"\u2705 Modelo Generalizando Bem!\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. \ud83e\uddea Teste Externo (Prova Real)\n",
    "Validamos o modelo com um dataset TOTALMENTE NOVO que o modelo nunca viu.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83c\udf0d Baixando Dataset de Teste Externo...\")\n",
    "test_path = kagglehub.dataset_download(\"belsonraja/face-mask-dataset-with-and-without-mask\")\n",
    "TEST_DIR = os.path.join(test_path, \"facemask-dataset\", \"dataset\")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Aplica apenas o preprocessamento de valida\u00e7\u00e3o (normaliza\u00e7\u00e3o)\n",
    "test_dataset = test_dataset.map(preprocess_val).prefetch(AUTOTUNE)\n",
    "\n",
    "print(\"\\n\ud83e\uddea Avaliando no Dataset Externo...\")\n",
    "external_loss, external_acc = model.evaluate(test_dataset)\n",
    "print(f\"\ud83c\udfc6 Acur\u00e1cia no Teste Externo: {external_acc*100:.2f}%\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Visualiza\u00e7\u00e3o das Predi\u00e7\u00f5es no Teste\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega um batch de imagens\n",
    "image_batch, label_batch = next(iter(test_dataset))\n",
    "predictions = model.predict(image_batch)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "test_class_names = class_names # Classes salvas anteriormente\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i in range(min(16, len(image_batch))):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    \n",
    "    # Desnormaliza para mostrar\n",
    "    img_show = (image_batch[i] + 1) / 2\n",
    "    plt.imshow(img_show)\n",
    "    \n",
    "    true_label = test_class_names[label_batch[i]]\n",
    "    pred_label = test_class_names[predicted_classes[i]]\n",
    "    confidence = np.max(predictions[i]) * 100\n",
    "    \n",
    "    color = \"green\" if true_label == pred_label else \"red\"\n",
    "    \n",
    "    plt.title(f\"Real: {true_label}\\nPred: {pred_label}\\n({confidence:.1f}%)\", color=color, fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Predi\u00e7\u00f5es no Dataset Externo\", fontsize=16)\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. \ud83d\udcbe Exporta\u00e7\u00e3o Otimizada\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mask_detector_light.keras\")\n",
    "\n",
    "# TFLite Conversion\n",
    "print(\"\\n\ud83d\udd04 Convertendo para TFLite INT8...\")\n",
    "def representative_data_gen():\n",
    "    for input_value, _ in train_dataset.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = \"mask_detector_light_int8.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "size_kb = os.path.getsize(tflite_path) / 1024\n",
    "print(f\"\u2705 Modelo TFLite salvo: {tflite_path}\")\n",
    "print(f\"\ud83d\udce6 Tamanho Final: {size_kb:.2f} KB\")\n",
    "\n",
    "if size_kb < 400:\n",
    "    print(\"\ud83c\udf89 SUCESSO! Meta de < 400KB atingida.\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f Ainda acima de 400KB. Tente reduzir input_shape ou alpha.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}